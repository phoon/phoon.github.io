[{"categories":["后端","系统设计"],"content":"楔子 最近再次翻看《InnoDB存储引擎》，看到Doublewrite时，直觉告诉我这玩意儿应该很简单（其实确实是），但总感觉书上的文字表达不够清晰，再加上这背后涉及到的底层知识其实也挺有趣的，遂各处寻解并作此文以记录。内容出于个人理解，有错误的地方还请指正。 ","date":"2021-10-06","objectID":"/post/2021/10/06/innodb-doublewrite/:1:0","tags":["InnoDB","Doublewrite"],"title":"InnoDB Doublewrite机制","uri":"/post/2021/10/06/innodb-doublewrite/"},{"categories":["后端","系统设计"],"content":"InnoDB逻辑存储结构 在正式开始介绍Doublewrite技术前，先来粗略的看一下InnoDB存储引擎的逻辑存储结构： InnoDB逻辑存储结构 InnoDB中所有的数据都逻辑地存放在表空间（Tablespace）中，且默认会有一个共享的表空间ibdata1（若启用了innodb_file_per_table参数，则每张表内的数据可单独放于一个表空间内）；表空间用来存放页（Page），也即InnoDB引擎进行磁盘管理的最小单位，页内按行存储了我们的实际数据，页大小由innodb_page_size参数设置，默认为16KB；一定数量的连续的页面会组成一个区（Extent），而区的大小则有以下规则限定： Page Size Consecutive Pages Count Extent Size 4KB 256 1MB 8KB 128 1MB 16KB 64 1MB 32KB 64 2MB 64KB 64 4MB 进而由多个区所构成的表空间文件叫做段（Segment），如数据段（图中Leaf-node segment）、索引段（图中Non-Leaf-node segment）、回滚段（图中Rollback segment，但注意：与其它段不同，回滚段里包含了其它的表空间段）等。 对于InnoDB存储引擎的逻辑存储结构先介绍到这里，接下来我们来看InnoDB存储引擎里非常重要的Doublewrite特性。 ","date":"2021-10-06","objectID":"/post/2021/10/06/innodb-doublewrite/:2:0","tags":["InnoDB","Doublewrite"],"title":"InnoDB Doublewrite机制","uri":"/post/2021/10/06/innodb-doublewrite/"},{"categories":["后端","系统设计"],"content":"Doublewrite机制 ","date":"2021-10-06","objectID":"/post/2021/10/06/innodb-doublewrite/:3:0","tags":["InnoDB","Doublewrite"],"title":"InnoDB Doublewrite机制","uri":"/post/2021/10/06/innodb-doublewrite/"},{"categories":["后端","系统设计"],"content":"页断裂问题 页断裂，亦称部分写失效（partial page write），描述的是这样一个问题：恰逢系统宕机时，InnoDB正在更新/写入一个页的数据，可能会导致数据只完成部分写入，而剩余的部分的数据则是无效数据或者陈旧数据。 发生这个问题的原因在于，对于InnoDB页的更新/写入不具备原子性。不具备原子性是因为：太大了（InnoDB页大小最小设置都得4KB，当然太小也不可取，这里仅为说明页断裂戏谑几句）。不像重做日志（redo log），redo-log的块大小为512字节，与磁盘扇区大小一致——对于磁盘来说，使用扇区作为最小传输单位，传统上扇区长度即为512字节。所以redo-log的写入可以保证原子性：因为从硬件设计上来说，现代硬盘自身的电量会足够完成断电后一个扇区的写入操作，以此保证原子性。 而发生页断裂后，要进行修复的前提是，我们得有一份该页的副本。InnoDB默认会在加载页时对其进行完整性校验（Page Header和Page Trailer中记录了LSN数据），校验未通过则表明该页可能有页断裂问题，这时需要对该页进行恢复。有的人疑惑为什么这里不能通过redo log来对断裂页进行修复，因为redo log是根据页中的LSN来判断页是否需要进行恢复，换句话说，redo log根本解决不了页断裂的问题，毕竟该页面已经损坏了，无法提供信息给redo log参考。所以我们得重新写入该页面，而在哪里重新再获取到这个页面呢？ ","date":"2021-10-06","objectID":"/post/2021/10/06/innodb-doublewrite/:3:1","tags":["InnoDB","Doublewrite"],"title":"InnoDB Doublewrite机制","uri":"/post/2021/10/06/innodb-doublewrite/"},{"categories":["后端","系统设计"],"content":"解决之道 为了解决上面提到的问题，InnoDB引入了Doublewrite机制。其作用就是保存一份最近更新过的页的副本，方便发生页断裂时进行页恢复，从而保证在遇到系统宕机时写页面的原子性和持久性。由局部性（程序通常倾向于引用临近于其他最近引用过的数据项的数据项，抑或最近引用过的数据项本身）可知，这样的机制应该会有不错的效果表现。 doublewrite架构 Doublewrite由两部分构成：内存中的doublewrite buffer以及共享表空间里的2个区（128个连续的页），它们的总大小都是2MB。 这里使用两个Extent分两次写入还有一个用处：双重缓冲。当在对一个区进行写入时，对应的另一个区的Doublewrite buffer还可以继续缓冲待flush的脏页。 在对内存缓冲池中的脏页进行flush时的步骤如下（此前对页的更改已经记录至redo log）： 不直接写磁盘，先拷贝至doublewrite buffer； doublewrite buffer分两次，每次1MB顺序地写入到共享表空间，随后立即调用fsync确保落盘； 然后再次将doublewrite buffer的页写入到实际的数据文件，同样的调用fsync落盘。 随后在出现需要进行页修复时，系统就可以在共享表空间内找到该页的一个副本，然后复制覆盖。 ","date":"2021-10-06","objectID":"/post/2021/10/06/innodb-doublewrite/:3:2","tags":["InnoDB","Doublewrite"],"title":"InnoDB Doublewrite机制","uri":"/post/2021/10/06/innodb-doublewrite/"},{"categories":["后端","系统设计"],"content":"References 《Mysql技术内幕：InnoDB存储引擎》: https://www.amazon.cn/dp/B00ETOV48K 《File Space Management – MySQL 8.0 Reference Manual》: https://dev.mysql.com/doc/refman/8.0/en/innodb-file-space.html [Paper] InnoDB DoubleWrite Buffer as Read Cache using SSDs∗ : https://www.usenix.org/legacy/events/fast12/poster_descriptions/Kangdescription2-12-12.pdf ","date":"2021-10-06","objectID":"/post/2021/10/06/innodb-doublewrite/:4:0","tags":["InnoDB","Doublewrite"],"title":"InnoDB Doublewrite机制","uri":"/post/2021/10/06/innodb-doublewrite/"},{"categories":["算法"],"content":"概览 算法实现概要 ","date":"2021-09-04","objectID":"/post/2021/09/04/raft-in-breif/:1:0","tags":["raft","Distributed System"],"title":"Raft in breif","uri":"/post/2021/09/04/raft-in-breif/"},{"categories":["算法"],"content":"安全性保证 Raft保证以下五条准则在算法运行期间始终成立(Invariance): Election Safety: 一个世代term内至多产生一个leader. Leader Append-Only: leader在自己的日志中只会追加新Entry而不会去修改或删除某一项Entry. Log Matching: 若俩日志中某Entry有着相同的index和term, 则该Entry之前的日志项都相同. Leader Completeness: 若一个Entry在某世代term内已committed, 则此后任何term内该Entry都存在. State Machine Safety: 若状态机应用了某Entry, 则该index处不应再应用其他Entry. ","date":"2021-09-04","objectID":"/post/2021/09/04/raft-in-breif/:2:0","tags":["raft","Distributed System"],"title":"Raft in breif","uri":"/post/2021/09/04/raft-in-breif/"},{"categories":["算法"],"content":"Leader选举 节点角色状态转移 选举Leader思想很简单: 某个节点开始竞选某个世代term的leader, 向其他节点发送RequestVote RPC, 如果他得到的支持票数满足quorum机制, 则成为该term内合法的leader. 这里面的关键问题是如何防止出现split brain问题(确保每个term内仅会出现一个leader). 首先, 对于一个给定的Term, 服务器只会进行一次投票(且只会投给Term更高的), 且为了避免出现过多的竞选者, 各节点的触发选举超时时间应随机化. 此外, RequestVoteRPC里还应带上候选者的日志信息, 避免选出落后的Leader而导致日志覆盖(违背线性化). ","date":"2021-09-04","objectID":"/post/2021/09/04/raft-in-breif/:3:0","tags":["raft","Distributed System"],"title":"Raft in breif","uri":"/post/2021/09/04/raft-in-breif/"},{"categories":["算法"],"content":"日志复制 要点: 大部分节点(quorum)已知晓的Entry的状态即为已committed, Leader会将其应用到状态机（持久化），返回客户端执行结果. Leader在下一次的AppendEntries RPC中带上commitedIndex，这样followers就知道自己相应的日志项也该应用到状态机了. Leader在AppendEntries RPC中带上新Entry之前的Entry信息，follower若检查到自己没有该Entry的话，就会知道自己之前的复制可能出了差错并拒绝掉该Entry. 只要follower的结果返回了成功, 我们就知道该follower与leader至少在新Entry之前是保持一致了的. Leader宕机带来的不一致问题(复制以Leader为准则): Leader通过AppendEntries RPC不断来回的试探到follower与之匹配的日志记录, 然后将其覆盖重写为与自己一致的项. 新Leader产生后, 可以先复制一个no-op Command的Entry从而更快的获得各follower的复制进度. 对前任的遗留日志需通过提交自己任期的日志去进行间接提交. 原因如下: 提交前任遗留日志 a: 此时$S_1$成为term 2的leader并产生了Entry, 只复制到了$S_2$后就crash了; b: $S_5$成为term 3的leader并产生了Entry, 但还没复制就crash了; c: $S_1$成为term 4的leader并产生了Entry, 他先复制前任的遗留Entry到了大多数节点, 但还没持久化提交就又crash了; d: $S_5$成为新term的leader, 未产生Entry, 接着它复制前任遗留的Entry, 并导致了日志重写. 可以看到, 由于策略是上来就提交前任的遗留Entry, 导致了日志被重写. 正确做法的结果应如e: c时刻$S_1$成为leader后, 等待到提交自己任期的Entry, 前任的遗留日志自然会被复制从而被间接提交. 且此后$S_5$由于落后的日志也不会再成功竞选. ","date":"2021-09-04","objectID":"/post/2021/09/04/raft-in-breif/:4:0","tags":["raft","Distributed System"],"title":"Raft in breif","uri":"/post/2021/09/04/raft-in-breif/"},{"categories":["算法"],"content":"成员(配置)变更 变更配置时, 可不是简单的直接从旧的配置换到新的上去就行(换配置然后重启). 为保证系统可用性和安全性, 应使用2-phase: 第一步: 禁止旧配置的系统继续接受新的请求 第二步: 切换到新的配置文件上 在新旧配置转换过渡期间会同时存在两种配置, 这期间系统可能会产生split brain. Raft采用的2-phase机制叫joint consensus: 其使得即使在过渡期间系统仍能正确的, 安全的运行: 如在$C_{old}$到$C_{new}$的过渡期: $C_{old, new}$ , 为防止split brain, 决议要同时通过两个配置的joint集合的quorum通过才行. 思考如下的配置拓扑: 3区域配置拓扑 如上图, 3个region(X, Y, Z)中配置$C_1$($X_2$, $Y_1$, $Z_1$) 组成的raft集群($Y_1$是leader)现在想要切换到配置$C_2$(新增$X_1$, 移除$X_2$). 先看看直接切换: 直接配置切换 可以看到, $Y_1$收到confchange后并切换到$C_2$, 与$X_1$组成了$C_2$的quorum, 与此同时, $X_2$与$Z_2$也组成了$C_1$的quorum, 这就导致了split brain. 而其中的原因是我们太过贪心, 将$X_1$的加入和$X_2$的移除同时进行了. 所以接下来我们先增加$X_1$, 再移除$X_2$(1 by 1, 让大部分节点知晓到第一次变更后再处理下一条). 则先$C_2$ = ($X_1$, $X_2$, $Y_1$, $Z_2$), 其quorum为3, 此时先变更的$X_1$与$Y_1$一起并无法做出决议. 但这样就真的完美解决了我们的问题吗? 若这时region X整个不可达时, 整个集群就得等待其重新上线才能恢复服务. 这时就引出了joint consensus: 针对上例, 我们在进行配置变更时, 引入过渡期配置$C_{1,2}$ = $C_1$ \u0026\u0026 $C_2$ = ($X_2$, $Y_1$, $Z_2$) \u0026\u0026 ($X_1$, $Y_1$, $Z_2$) , 过渡期间任何决议都得同时通过两个配置中的quorum通过才行: Joint consensus 这样, 即使X region整个失联, 集群仍是能够正常的运行. 使用joint consensus进行成员配置变更的大致流程如下: 配置变更流程 其中, 需要注意的问题是如果leader发生crash了会怎样? 由于有Leader completeness的保证, 在$C_{1,2}$ committed后, crash后新的leader的配置也一定会是$C_{1,2}$. 还有一种情况: $C_2$ committed后, leader可能并不在此配置中, 此时leader自己降级为follower, 进行$C_2$配置内的选举. 此外, Raft还针对新增的成员引入了一个新的角色: learner(可以看看这篇文章: etcd learner design). 在节点加入集群初期, 由于日志复制状态通常会远远落后于leader, learner在日志追赶未完成前不会参与决议投票. 而对于已移除(不在新配置中)但未下线的节点, 其在心跳超时后会发起RequestVote RPC反复干扰现有配置的集群, 避免的方式为只要节点认为现有leader还在(最小选举超时机制),就不理会新的RequestVote RPC. ","date":"2021-09-04","objectID":"/post/2021/09/04/raft-in-breif/:5:0","tags":["raft","Distributed System"],"title":"Raft in breif","uri":"/post/2021/09/04/raft-in-breif/"},{"categories":["算法"],"content":"日志压缩 我们不能允许日志记录无休止的增长, 必须对其进行压缩以使获得更小的空间占用和更高效的日志复制: 通过check point处的快照(Snapshot)记录保留committed entries的最新状态, 旧的日志条目就可以删除掉. Snapshot 参考Etcd raft库的设计: 该库将raftLog分为storage(stable)和unstable. Snapshot定义: message SnapshotMetadata { optional ConfState conf_state = 1 [(gogoproto.nullable) = false]; optional uint64 index = 2 [(gogoproto.nullable) = false]; optional uint64 term = 3 [(gogoproto.nullable) = false]; } message Snapshot { optional bytes data = 1; optional SnapshotMetadata metadata = 2 [(gogoproto.nullable) = false]; } storage.go: type Storage interface { // TODO(tbg): split this into two interfaces, LogStorage and StateStorage. // InitialState returns the saved HardState and ConfState information. InitialState() (pb.HardState, pb.ConfState, error) // Entries returns a slice of log entries in the range [lo,hi). // MaxSize limits the total size of the log entries returned, but // Entries returns at least one entry if any. Entries(lo, hi, maxSize uint64) ([]pb.Entry, error) // Term returns the term of entry i, which must be in the range // [FirstIndex()-1, LastIndex()]. The term of the entry before // FirstIndex is retained for matching purposes even though the // rest of that entry may not be available. Term(i uint64) (uint64, error) // LastIndex returns the index of the last entry in the log. LastIndex() (uint64, error) // FirstIndex returns the index of the first log entry that is // possibly available via Entries (older entries have been incorporated // into the latest Snapshot; if storage only contains the dummy entry the // first log entry is not available). FirstIndex() (uint64, error) // Snapshot returns the most recent snapshot. // If snapshot is temporarily unavailable, it should return ErrSnapshotTemporarilyUnavailable, // so raft state machine could know that Storage needs some time to prepare // snapshot and call Snapshot later. Snapshot() (pb.Snapshot, error) } // MemoryStorage implements the Storage interface backed by an // in-memory array. type MemoryStorage struct { // Protects access to all fields. Most methods of MemoryStorage are // run on the raft goroutine, but Append() is run on an application // goroutine. sync.Mutex hardState pb.HardState snapshot pb.Snapshot // ents[i] has raft log position i+snapshot.Metadata.Index ents []pb.Entry } log.go: type raftLog struct { // storage contains all stable entries since the last snapshot. storage Storage // unstable contains all unstable entries and snapshot. // they will be saved into storage. unstable unstable // committed is the highest log position that is known to be in // stable storage on a quorum of nodes. committed uint64 // applied is the highest log position that the application has // been instructed to apply to its state machine. // Invariant: applied \u003c= committed applied uint64 logger Logger // maxNextEntsSize is the maximum number aggregate byte size of the messages // returned from calls to nextEnts. maxNextEntsSize uint64 } log_unstable.go: // unstable.entries[i] has raft log position i+unstable.offset. // Note that unstable.offset may be less than the highest log // position in storage; this means that the next write to storage // might need to truncate the log before persisting unstable.entries. type unstable struct { // the incoming unstable snapshot, if any. snapshot *pb.Snapshot // all entries that have not yet been written to storage. entries []pb.Entry offset uint64 logger Logger } 用一张图来直观的展示: Etcd raft日志结构 ","date":"2021-09-04","objectID":"/post/2021/09/04/raft-in-breif/:6:0","tags":["raft","Distributed System"],"title":"Raft in breif","uri":"/post/2021/09/04/raft-in-breif/"},{"categories":["算法"],"content":"See Also Raft Paper: https://raft.github.io/raft.pdf Etcd Raft lib: https://github.com/etcd-io/etcd/tree/main/raft Availability and Region Failure: Joint Consensus in CockroachDB: https://www.cockroachlabs.com/blog/joint-consensus-raft ","date":"2021-09-04","objectID":"/post/2021/09/04/raft-in-breif/:7:0","tags":["raft","Distributed System"],"title":"Raft in breif","uri":"/post/2021/09/04/raft-in-breif/"},{"categories":["折腾"],"content":" 不定时补充更新 ","date":"2021-08-21","objectID":"/post/2021/08/21/dgraph-memo/:0:0","tags":["dgraph"],"title":"Dgraph备忘录","uri":"/post/2021/08/21/dgraph-memo/"},{"categories":["折腾"],"content":"部署 docker pull dgraph/dgraph # HOSTIPADDR=10.0.0.10 # 用以后续告知raft模块通信地址,确保集群连通性, 我这儿后面直接写了 cd .. mkdir -p Dgraph # 创建服务用户 groupadd dgraph useradd -M -g dgraph -s /usr/sbin/nologin dgraph chown -R dgraph:dgraph Dgraph # 生成TLS证书 # client证书用于mtls, SAN(Subject Alternative Name) 取决于访问时需要用到的标识(localhost, 公网IP...) docker run --rm -v ~/Dgraph:/dgraph dgraph/dgraph:latest dgraph cert -n $SAN -c zero1 docker run --rm -v ~/Dgraph:/dgraph dgraph/dgraph:latest dgraph cert -c alpha1 # zero docker run -d --name dgraph-zero-1 --network dgraph_default -p 6080:6080 -p 5080:5080 -v ~/Dgraph:/dgraph dgraph/dgraph:latest dgraph zero --my=10.0.0.10:5080 --tls \"ca-cert=/dgraph/tls/ca.crt;client-auth-type=REQUIREANDVERIFY;server-cert=/dgraph/tls/node.crt;server-key=/dgraph/tls/node.key;internal-port=true;client-cert=/dgraph/tls/client.zero1.crt;client-key=/dgraph/tls/client.zero1.key\" # alpha docker run -d --name dgraph-alpha1 --network dgraph_default -p 7080:7080 -p 9080:9080 -p 8080:8080 -v ~/Dgraph:/dgraph dgraph/dgraph:latest dgraph alpha --zero=10.0.0.10:5080 --my=10.0.0.10:7080 --badger \"compression=zstd:1\" --security \"whitelist=0.0.0.0/0\" --tls \"ca-cert=/dgraph/tls/ca.crt;client-auth-type=REQUIREANDVERIFY;server-cert=/dgraph/tls/node.crt;server-key=/dgraph/tls/node.key;internal-port=true;client-cert=/dgraph/tls/client.alpha1.crt;client-key=/dgraph/tls/client.alpha1.key\" # 给浏览器签发证书(自己导入ca.crt和.p12文件) # 同样的,可以给需要连接的客户端签发证书 docker run --rm -v ~/Dgraph:/dgraph dgraph/dgraph:latest dgraph cert -c browser openssl pkcs12 -export -out Dgraph/browser.p12 -in Dgraph/tls/client.browser.crt -inkey Dgraph/tls/client.browser.key 端口占用情况: Dgraph Node Type gRPC-internal-private gRPC-external-private gRPC-external-public HTTP-external-private HTTP-external-public zero 5080 5080 6080 alpha 7080 9080 8080 ratel 8000 ","date":"2021-08-21","objectID":"/post/2021/08/21/dgraph-memo/:1:0","tags":["dgraph"],"title":"Dgraph备忘录","uri":"/post/2021/08/21/dgraph-memo/"},{"categories":["折腾"],"content":"Triples Dgraph采用的图数据模型是Triples(三元组), 也即S P O, 展开表示为: \u003cSubject\u003e \u003cPredicate\u003e \u003cObject\u003e. 也即图中由subject标识的节点通过有向边predicate连接到object. 同时借助RDF(资源描述框架, 基于语义网的知识表示框架)来增强其数据关联性. ","date":"2021-08-21","objectID":"/post/2021/08/21/dgraph-memo/:2:0","tags":["dgraph"],"title":"Dgraph备忘录","uri":"/post/2021/08/21/dgraph-memo/"},{"categories":["折腾"],"content":"Blank UID { set { _:alice \u003cname\u003e \"Alice\" . _:bob \u003cname\u003e \"Bob\" _:bob \u003cfollows\u003e _:alice . # assign type _:alice \u003cdgraph.type\u003e \"Person\" . _:bob \u003cdgraph.type\u003e \"Person\" . } } _:alice 并不是真正的uid, 其在这里就是一个uid的placeholder(数据还未真正创建), 可以在set 阶段去引用某对象的uid. ","date":"2021-08-21","objectID":"/post/2021/08/21/dgraph-memo/:3:0","tags":["dgraph"],"title":"Dgraph备忘录","uri":"/post/2021/08/21/dgraph-memo/"},{"categories":["折腾"],"content":"Schema里的\u003c\u003e 简单来说, 如果你的predicate名并不是由数字及字母组成, 在执行mutation时就需要用\u003c\u003e括起来. If your predicate is a URI or has language-specific characters, then enclose it with angle brackets \u003c\u003e when executing the schema mutation. ","date":"2021-08-21","objectID":"/post/2021/08/21/dgraph-memo/:4:0","tags":["dgraph"],"title":"Dgraph备忘录","uri":"/post/2021/08/21/dgraph-memo/"},{"categories":["折腾"],"content":"Expand a type { data(func: type(Person)) { expand(_all_) { expand(_all_) } } } 通过指定type函数参数为某type, 会自动展开结果中该type的字段(predicate). ","date":"2021-08-21","objectID":"/post/2021/08/21/dgraph-memo/:5:0","tags":["dgraph"],"title":"Dgraph备忘录","uri":"/post/2021/08/21/dgraph-memo/"},{"categories":["折腾"],"content":"Reverse edges 在predicate定义里加上@reverse, 可通过~来取反. ","date":"2021-08-21","objectID":"/post/2021/08/21/dgraph-memo/:6:0","tags":["dgraph"],"title":"Dgraph备忘录","uri":"/post/2021/08/21/dgraph-memo/"},{"categories":["折腾"],"content":"Password type Dgraph提供了password类型, 表现为加密后的string, 其实是使用bcrypt加密生成的密文(60字节). ","date":"2021-08-21","objectID":"/post/2021/08/21/dgraph-memo/:7:0","tags":["dgraph"],"title":"Dgraph备忘录","uri":"/post/2021/08/21/dgraph-memo/"},{"categories":["折腾"],"content":"@upsert 给predicate添加此directive, 以使提交事务时Dgraph可以检查索引是否有冲突, 从而达到unique index的效果. \u003cemail\u003e: string @index(hash) @upsert . 使用upsert block: 发起一个新事务 先query, 如果成功返回了uid则说明该结点已经存在, 反则说明不存在 若不存在, 则会创建新结点(紧接着的mutation) upsert { query { q(func: eq(email, \"user@company1.io\")) { v as uid name } } mutation { set { # 若uid有值 uid(v) \u003cname\u003e \"first last\" . uid(v) \u003cemail\u003e \"user@company1.io\" . } } } ","date":"2021-08-21","objectID":"/post/2021/08/21/dgraph-memo/:8:0","tags":["dgraph"],"title":"Dgraph备忘录","uri":"/post/2021/08/21/dgraph-memo/"},{"categories":["折腾"],"content":"GraphQL \u0026 DQL 说实话, Dgraph的文档还是有些糟糕, 你所需的信息可能藏在你根本想不到的角落(尽量将所有文档概览一下), 这个主题来自这篇Blog. 早期Dgraph是直接使用GraphQL作为数据库查询语言, 但很显然, GraphQL设计的初衷是用于API的, 只是语法看起来很\"graph\", 所以很快就展现出了其局限性: A DQL schema is predicate-first focused and supports some aspects not yet supported by the GraphQL syntax such as multi-lingual predicates and facets (data information stored on edges between nodes). A GraphQL schema is type-first focused and only supports spec-compliant elements. DQL是Dgraph基于GraphQL魔改的一套适于图数据库原生的查询语言, 事实上Dgraph核心只使用DQL, 任何传入的GraphQL请求都会先被重写为DQL. 简单来说, 直接使用GraphQL Endpoint也未尝不可, Dgraph本身也可以是GraphQL Native, 但无论如何, 其内部还是使用的DQL, 其会据GraphQL的schema'生成一份等同的DQL schema, 反之则不然. GraphQL Endpoint可以配备访问权限控制(@auth directive... 等), DQL更适合传统的后端开发(先查询数据, 做点自定操作然后再返回). ","date":"2021-08-21","objectID":"/post/2021/08/21/dgraph-memo/:9:0","tags":["dgraph"],"title":"Dgraph备忘录","uri":"/post/2021/08/21/dgraph-memo/"},{"categories":["折腾"],"content":"数据存储 Dgraph数据使用Badger存储, 一个基于LSM-Tree的KV数据库, 其设计使得它理论上能够很好的降低读写放大的问题. Dgraph的图数据模型是Triples, 在存储时: 所有相同predicate的记录组成一个shard, 在该shard中, 具有同一\u003csubject - predicate\u003e关系的的记录会被组合浓缩成一条K-V对存储在Badger中. 该value又叫做posting list(搜索引擎术语, 根据搜索的term找到的排序好的文档ids). posting list作为一个value存储在Badger中, 而其key由subject及predicate共同推导而得. \u003c0x01\u003e \u003cfollower\u003e \u003c0xab\u003e . \u003c0x01\u003e \u003cfollower\u003e \u003c0xbc\u003e . \u003c0x01\u003e \u003cfollower\u003e \u003c0xcd\u003e . ... key = \u003cfollower, 0x01\u003e value = \u003c0xab, 0xbc, 0xcd, ...\u003e 在Dgraph中你可以使用debug子命令来观察posting list结构: docker stop dgraph-alpha # 或复制一份p文件夹 docker debug -p Dgrpah/p # 具体使用方法 docker debug -h ","date":"2021-08-21","objectID":"/post/2021/08/21/dgraph-memo/:10:0","tags":["dgraph"],"title":"Dgraph备忘录","uri":"/post/2021/08/21/dgraph-memo/"},{"categories":["Golang","算法"],"content":" 前置知识：二叉查找树、B树，本文不多做介绍。 ","date":"2021-05-08","objectID":"/post/2021/05/08/the-red-black-tree/:0:0","tags":["红黑树"],"title":"红黑树那点事儿","uri":"/post/2021/05/08/the-red-black-tree/"},{"categories":["Golang","算法"],"content":"0. 写在前面 在观察和思考红黑树时，一定要牢记：红黑树是一颗平衡二叉查找树，我们所赋予红黑树的一切行为，都是为了使其能够保持平衡性。 红黑树是由2-3-4树（4阶B树）等价过来的（当然也有由2-3树等价来的左倾或右倾红黑树），而这层等价关系，是我们用以维持红黑树平衡性的根本。 在红黑树中，我们以黑色来标识对应B树里的2-结点，而红色结点表示其parent到自己的链接是一条红链接（向上融合后对应B树中的3-结点，若兄弟结点也是红色则一起向上融合对应4-结点） 接下来我们来看看红黑树的五大性质： 结点为红色或黑色 根为黑色 NULL叶子结点均为黑色 每个叶子结点到根的路径上不能有两个连续的红色结点 完美黑色平衡 通过前面展示的等价关系，要推导出这几条性质不成问题。 ","date":"2021-05-08","objectID":"/post/2021/05/08/the-red-black-tree/:1:0","tags":["红黑树"],"title":"红黑树那点事儿","uri":"/post/2021/05/08/the-red-black-tree/"},{"categories":["Golang","算法"],"content":"1. 旋转以及颜色翻转的本质 首先我们要明确一个概念：旋转是作用于红链接的操作。那么，旋转操作到底给我们的红黑树带来了怎样的影响呢？ ","date":"2021-05-08","objectID":"/post/2021/05/08/the-red-black-tree/:2:0","tags":["红黑树"],"title":"红黑树那点事儿","uri":"/post/2021/05/08/the-red-black-tree/"},{"categories":["Golang","算法"],"content":"Ⅰ. 旋转 旋转分为左旋（left-rotate）和右旋（right-rotate）： 左旋：将右红链接转换为左红链接 右旋：将左红链接转换为右红链接 可以看到：在经过旋转操作后，我们可以调节某一侧黑色结点的平衡，而对应的2-3-4树结点并未发生任何变化。 ","date":"2021-05-08","objectID":"/post/2021/05/08/the-red-black-tree/:2:1","tags":["红黑树"],"title":"红黑树那点事儿","uri":"/post/2021/05/08/the-red-black-tree/"},{"categories":["Golang","算法"],"content":"Ⅱ. 颜色翻转（flip-color） 颜色翻转其实对应的是2-3-4树中4-结点需要分裂时的情况：一个新的KEY想要加入4-结点，会导致原有的4-结点分裂，原来中间的KEY会提到上层进行融合。 当我们插入d时，会形成一个临时5-结点，这时原先的4-结点将分裂，将b提上去进行融合（标为红色），当然，若此时b已经成为根节点，则进一步标为黑色。可以看到，我们通过简单的颜色翻转即可达到2-3-4树中结点分裂的效果。 ","date":"2021-05-08","objectID":"/post/2021/05/08/the-red-black-tree/:2:2","tags":["红黑树"],"title":"红黑树那点事儿","uri":"/post/2021/05/08/the-red-black-tree/"},{"categories":["Golang","算法"],"content":"2. 平衡性维持 在我们按照二叉查找树的规则做完插入或删除操作之后，就要通过观察对应2-3-4树中的变化，对我们的红黑树进行等价的操作从而恢复对应关系（即维持红黑树的平衡性）。 ","date":"2021-05-08","objectID":"/post/2021/05/08/the-red-black-tree/:3:0","tags":["红黑树"],"title":"红黑树那点事儿","uri":"/post/2021/05/08/the-red-black-tree/"},{"categories":["Golang","算法"],"content":"Ⅰ. 插入后的平衡性维持 新的结点作为红色叶子结点插入到树中，无非为以下4种情况： a. 新增一个2-结点 如果新增的2-结点将作为根节点，则将其进一步标为黑色。 b. 与一个2-结点合并成为3-结点 即新结点的parent结点为黑色，无需调整。 c. 与一个3-结点合并成为4-结点 图中黑色虚线方框内是插入新节点时其parent结点以及grandparent结点可能的情形 橙色三角标所指表示我们新插入的结点的位置 可能会出现连续两条红链接的情况，这时需要通过旋转操作进行调整（为上图下半部分的形式）。 d. 与一个4-结点进行合并， 4-结点需要分裂（颜色翻转） ","date":"2021-05-08","objectID":"/post/2021/05/08/the-red-black-tree/:3:1","tags":["红黑树"],"title":"红黑树那点事儿","uri":"/post/2021/05/08/the-red-black-tree/"},{"categories":["Golang","算法"],"content":"Ⅱ. 删除后的平衡性维持 删除操作同BST大体相同，不过在我们的代码实现里，被删除的永远是一个替代结点。因为红黑树由2-3-4树等价而来，我们要充分对其性质进行利用。 那么替代结点究竟如何得到呢？我们先查找到指定删除的结点d，如果该结点有两个孩子，则替代结点为其前驱或后继结点；如果该结点只有一个孩子，该孩子就是替代结点；若d没有孩子（即d为根结点），则替代结点就是其本身。 因为2-3-4树的完美平衡性质，我们可以得到一个结论：真正被删除的元素一定是2-3-4树中的叶子节点中的KEY，也即在红黑树中删除的（替代结点）一定是叶子节点或者叶子结点上面的双亲结点（最多只有一个孩子）。 进一步得出以下推论：若替代结点的左孩子不为空，则替代结点一定是一个前驱结点；反之，是一个后继结点。删除后用其子节点替代自己的位置。 而这又对应了2-3-4树中叶子结点的状况： 2-结点：删除后兄弟够借，经过双亲借；兄弟不够，啃老来凑 非2-结点：自己足够，直接删除 而后我们的删除策略就变成了（以用前驱结点替代为例）： 若删除的替代结点有孩子，且替代结点为黑色，将孩子变为黑色来替代自己 删除的是一个叶子节点，且这个替代结点为黑色，在删除前先进行平衡修复（避免提前删除导致信息丢失） 接下来讨论上述第二种情况：需要平衡修复的情况。 a. 兄弟够借 向兄弟结点借之前得先知道兄弟手里够不够吧，所以需要找到真正的兄弟结点，因为若当前替代结点的兄弟是红色结点的话，对应2-3-4树，在红黑树中根本不是真正的兄弟结点。如下图第二种情况（图中p表示parent结点哦）： 这时我们只需对替代结点的parent结点做一次旋转操作即可（出现红链接了）,如下所示： 找到真正的兄弟结点之后，如果兄弟结点的孩子中有红色结点，就对应了2-3-4树中非2-结点可借的情况。 既然兄弟够借，那么对应2-3-4树中，就是兄弟中KEY最接近自己的上去顶替parent，parent下来顶替被删的结点。 为了实现起来简单，这里有一个小trick：通过旋转将兄弟与兄弟孩子结点达到某种关系后，再旋转parent结点。这样做可以达到在对应2-3-4树中如果有兄弟有两个孩子就从兄弟那里借两个来的效果，而且可以大大的简化我们的代码。 例如被删结点是其parent的左孩子，找到其真正的右兄弟后，如果右兄弟有两个红色子节点，直接旋转parent，这样，兄弟结点中只会留下右孩子（较大的KEY），兄弟结点上升代替parent，parent与兄弟左孩子下来代替删除的结点，左孩子没有的话也没关系；另一种需要提前调整的情况是，右兄弟只有一个左孩子可借，这时候我们对右兄弟进行右旋后再对parent进行左旋即可。 然而我们前面说：旋转操作是针对红链接的。然而我们在这里其实很幸运地跳出了这个规则的束缚,只需做小许额外的步骤： 对parent旋转之后， 兄弟顶上去替代parent的位置， 兄弟被染成了parent原来的颜色 —— 上去顶替,没毛病 但parent变成了红色，不过因为parent是下来顶替被删的黑色结点，故需将其染成黑色 最后，将兄弟结点之前的右孩子标为黑色 —— 只剩下它了，作为一个2-结点 若被删结点是其parent的右孩子，把上面的逻辑反过来左右对调即可。 如果真兄弟结点的两个孩子均为黑色，就对应了2-结点、不可借的情况，我们将在下面继续进行讨论。 b. 兄弟不够 兄弟无法借过来，对应2-3-4树中，兄弟就得找parent合并。所以直接将兄弟结点变成红色，交由上层解决。若parent也是红色，就把parent变成黑色。若parent本身就是黑色，就得让parent再找他自己的兄弟结点借。 ","date":"2021-05-08","objectID":"/post/2021/05/08/the-red-black-tree/:3:2","tags":["红黑树"],"title":"红黑树那点事儿","uri":"/post/2021/05/08/the-red-black-tree/"},{"categories":["Golang","算法"],"content":"3. 代码实现 package rbt const ( RED = true BLACK = false ) type ( // KeyType is the type with CompareTo behavior. KeyType interface { CompareTo(c interface{}) int } // KeyTypeInt is the int that implements the KeyType interface. KeyTypeInt int // node is the red-black tree node node struct { Key KeyType Val interface{} Color bool Left *node Right *node Parent *node } // RBT is the red-black tree RBT struct { root *node size int } ) // CompareTo implementation for type KeyTypeInt func (k KeyTypeInt) CompareTo(c interface{}) int { return int(k) - int(c.(KeyTypeInt)) } // isRed returns whether a node is in red color, nil is black func isRed(n *node) bool { if n == nil { return BLACK } return n.Color } // NewRBT returns a red-black tree func NewRBT() *RBT { return \u0026RBT{} } // treeMin find the minimum node in n's sub-tree // func (n *node) treeMin() *node { // for n.Left != nil { // n = n.Left // } // return n // } // treeMax find the maximum node in n's sub-tree func (n *node) treeMax() *node { for n.Right != nil { n = n.Right } return n } // predecessor returns n's predecessor node func (n *node) predecessor() *node { if n == nil { return nil } if n.Left != nil { return n.Left.treeMax() } else { p := n.Parent lc := n for p != nil \u0026\u0026 lc == p.Left { lc = p p = p.Parent } return p } } // successor returns n's successor node // func (n *node) successor() *node { // if n == nil { // return nil // } // if n.Right != nil { // return n.Right.treeMin() // } else { // p := n.Parent // lc := n // for p != nil \u0026\u0026 lc == p.Right { // lc = p // p = p.Parent // } // return p // } // } // LeftRotate left rotate the node n, acting on a red link // // p p // | | // n m // / \\ / \\ // nl m ==\u003e n mr // / \\ / \\ // ml mr nl ml // func (t *RBT) leftRotate(n *node) { m := n.Right n.Right = m.Left if m.Left != nil { m.Left.Parent = n } m.Parent = n.Parent if n.Parent == nil { t.root = m } else if n == n.Parent.Left { n.Parent.Left = m } else { n.Parent.Right = m } m.Left = n n.Parent = m // repaint color m.Color = n.Color n.Color = RED } // RightRotate right rotate the node n, acting on a red link // // p p // | | // n m // / \\ / \\ // m nr ==\u003e ml n // / \\ / \\ // ml mr mr nr // func (t *RBT) rightRotate(n *node) { m := n.Left n.Left = m.Right if m.Right != nil { m.Right.Parent = n } m.Parent = n.Parent if n.Parent == nil { t.root = m } else if n == n.Parent.Left { n.Parent.Left = m } else { n.Parent.Right = m } m.Right = n n.Parent = m // repaint color m.Color = n.Color n.Color = RED } func (t *RBT) flipColors(n *node) { n.Color = RED n.Left.Color = BLACK n.Right.Color = BLACK } // Search returns the node by the given key if it exists func (t *RBT) Search(key KeyType) *node { root := t.root for root != nil { cmp := key.CompareTo(root.Key) if cmp \u003c 0 { root = root.Left } else if cmp \u003e 0 { root = root.Right } else { return root } } return root } // Insert inserts a key with associated data(val) to a place in the red-black // tree by compare the keys, and if the key exists, update it with the new val. func (t *RBT) Insert(key KeyType, val interface{}) { if t.root == nil { t.root = \u0026node{Key: key, Val: val} t.size = 1 return } // find parent node to attach root := t.root var p *node for root != nil { p = root cmp := key.CompareTo(root.Key) if cmp \u003c 0 { root = root.Left } else if cmp \u003e 0 { root = root.Right } else { root.Val = val return } } newnode := \u0026node{Key: key, Val: val, Color: RED, Parent: p, } cmp := key.CompareTo(p.Key) if cmp \u003c 0 { p.Left = newnode } else { p.Right = newnode } t.insertFix(newnode) t.size++ } func (t *RBT) insertFix(n *node) { var u *node // n's uncle node for n.Parent != nil \u0026\u0026 isRed(n.Parent) { if n.Parent == n.Parent.Parent.Left { u = n.Parent.Parent.Right if u != nil \u0026\u0026 isRed(u) { n = n.Parent.Parent t.flipColors(n) } else { if n == n.Parent.Right { n = n.Parent t.leftRotate(n) } t.rightRotate(n.Parent.Parent) } } else { u = n.Parent.Parent.Left if u != nil \u0026\u0026 isRed(u) { n = n.Parent.Parent t.flipColors(n) } else { if n == n.Parent.Lef","date":"2021-05-08","objectID":"/post/2021/05/08/the-red-black-tree/:4:0","tags":["红黑树"],"title":"红黑树那点事儿","uri":"/post/2021/05/08/the-red-black-tree/"},{"categories":["Golang","算法"],"content":"4. Do something fun：红黑树可视化 用graphviz库（需自行安装dot工具包）给我们的红黑树实现了Visualize方法： func (t *RBT) Visualize() { G := visuzlizeTree(t.root) G.GenerateImage(\"dot\", \"rbt.svg\", \"svg\") } func visuzlizeTree(root *node) *graphviz.Graph { G := \u0026graphviz.Graph{} addSubTree(root, G) G.DefaultNodeAttribute(graphviz.Shape, graphviz.ShapeCircle) G.DefaultNodeAttribute(graphviz.FontName, \"JetBrainsMono Nerd Font\") G.GraphAttribute(graphviz.NodeSep, \"0.3\") G.DefaultNodeAttribute(graphviz.Style, graphviz.StyleFilled) G.DefaultNodeAttribute(graphviz.FillColor, \"#B7BBBC\") // G.MakeDirected() return G } func addSubTree(root *node, G *graphviz.Graph) int { if root == nil { null := G.AddNode(\"\") G.NodeAttribute(null, graphviz.Shape, graphviz.ShapePoint) return null } rootnode := G.AddNode(fmt.Sprint(root.Key)) if root.isRed() { G.NodeAttribute(rootnode, graphviz.Style, graphviz.StyleFilled) G.NodeAttribute(rootnode, graphviz.FillColor, \"#F8BCC2\") } leftnode := addSubTree(root.Left, G) rightnode := addSubTree(root.Right, G) G.AddEdge(rootnode, leftnode, \"\") G.AddEdge(rootnode, rightnode, \"\") return rootnode } 调用生成rbt.svg： ","date":"2021-05-08","objectID":"/post/2021/05/08/the-red-black-tree/:5:0","tags":["红黑树"],"title":"红黑树那点事儿","uri":"/post/2021/05/08/the-red-black-tree/"},{"categories":["Golang","算法"],"content":"5. 总结 本文沿着红黑树同2-3-4树的关系脉络来讨论了红黑树里的插入及删除操作，其可能涉及的情况十分繁多，本文亦不能做到面面俱到。手绘的图也只展示了部分情况，力图通过简单的梳理来理解红黑树平衡性的本质。假如如果你此前对于B树已有很深入的理解的话，相信理解红黑树也不会花费太多时间。 ","date":"2021-05-08","objectID":"/post/2021/05/08/the-red-black-tree/:6:0","tags":["红黑树"],"title":"红黑树那点事儿","uri":"/post/2021/05/08/the-red-black-tree/"},{"categories":["折腾","Linux"],"content":"契机 最近入手了Logitech MX Anywhere 2S鼠标，欣喜的在Arch中连接上蓝牙一试，瞬间傻眼… 移动鼠标，指针掉帧严重，有很重的滞后感，运行evhz一看，平均polling rate只有22Hz, 这怎么玩嘛。 这里解释一下鼠标的polling rate：polling rate就是鼠标的轮询（刷新）率， 是鼠标向计算机报告其位置的频率，以Hz为单位。那么这里的22Hz意味着什么呢？当前鼠标每秒钟向计算机报告位置22次，也就是大约每45.5ms报告一次，不卡就怪了。 ","date":"2019-08-15","objectID":"/post/2019/08/15/anywhere2s-polling-issue-on-archlinux/:1:0","tags":["罗技"],"title":"解决Archlinux下蓝牙鼠标滞后感严重的问题","uri":"/post/2019/08/15/anywhere2s-polling-issue-on-archlinux/"},{"categories":["折腾","Linux"],"content":"解决方法 在各处论坛爬楼后，给出以下两种解决方案： 此处所示命令均为bash风格 ","date":"2019-08-15","objectID":"/post/2019/08/15/anywhere2s-polling-issue-on-archlinux/:2:0","tags":["罗技"],"title":"解决Archlinux下蓝牙鼠标滞后感严重的问题","uri":"/post/2019/08/15/anywhere2s-polling-issue-on-archlinux/"},{"categories":["折腾","Linux"],"content":"通过debugfs（内核调试） 运行以下命令： $ sudo echo 0 \u003e /sys/kernel/debug/bluetooth/hci0/conn_latency $ sudo echo 6 \u003e /sys/kernel/debug/bluetooth/hci0/conn_min_interval $ sudo echo 7 \u003e /sys/kernel/debug/bluetooth/hci0/conn_max_interval 路径中的hci0表示你电脑蓝牙接收器的名称 ","date":"2019-08-15","objectID":"/post/2019/08/15/anywhere2s-polling-issue-on-archlinux/:2:1","tags":["罗技"],"title":"解决Archlinux下蓝牙鼠标滞后感严重的问题","uri":"/post/2019/08/15/anywhere2s-polling-issue-on-archlinux/"},{"categories":["折腾","Linux"],"content":"借助hcitool工具 hcitool在Archlinux上已经弃用，不过你可以通过AUR来进行安装： $ yay -S bluez-hcitool 然后运行： $ export MOUSEHANDLE=`hcitool con | grep \"XX:XX:XX:XX:XX:XX\" | awk '{print $5}'` $ sudo hcitool lecup --handle $MOUSEHANDLE --min 6 --max 7 --latency 0 XX:XX:XX:XX:XX:XX替换为鼠标地址 ","date":"2019-08-15","objectID":"/post/2019/08/15/anywhere2s-polling-issue-on-archlinux/:2:2","tags":["罗技"],"title":"解决Archlinux下蓝牙鼠标滞后感严重的问题","uri":"/post/2019/08/15/anywhere2s-polling-issue-on-archlinux/"},{"categories":["折腾","Linux"],"content":"总结 ​ 在实施以上两种方案后，鼠标滞后感消失，在evhz下的polling rate值也上升到正常水平125Hz左右。不过使用第一种方案的话，目前不知道会不会出现意想不到的后果。而且经我实际体验，重启机器后即失效，并需要在再次运行命令之后删除设备然后重新配对连接之后才能再次生效；第二种方案，每次设备断线重连即失效，好处是不用删除设备重新配对连接。权衡之下，第二种解决方案还是更胜一筹，虽然这些都只是权宜之计罢了。 ","date":"2019-08-15","objectID":"/post/2019/08/15/anywhere2s-polling-issue-on-archlinux/:3:0","tags":["罗技"],"title":"解决Archlinux下蓝牙鼠标滞后感严重的问题","uri":"/post/2019/08/15/anywhere2s-polling-issue-on-archlinux/"},{"categories":["Linux"],"content":"译自 [The new pselect() system call] https://lwn.net/Articles/176911/ 像网络服务器等需要使用select()，poll()，或者epoll_wait()(Linux独有)等系统调用来对多个文件描述符进行监视的应用程序有时会面临这样一个问题：该如何等待其中的一个文件描述符变为ready状态，或者是接收一个signal（比如SIGINT）。因为事实表明，这些系统调用不能很好地与信号进行交互。 一个看似显而易见的解决方案是写一个空的信号处理器，以便传递信号从而中断select()的调用。 static void handler(int sig) {} int main(int argc, char *argv[]) { fd_set readfds; struct sigaction sa; int nfds, ready; sa.sa_handler = handler; /* Establish signal handler */ sigemptyset(\u0026sa.sa_mask); sa.sa_flags = 0; sigaction(SIGINT, \u0026sa, NULL); /* ... */ ready = select(nfds, \u0026readfds, NULL, NULL, NULL); /* ... */ 待到select()返回，我们就可以通过查看其返回值以及errno来确定发生了什么。如果errno是EINTR，我们就知道select()的调用被信号给中断了，并做出了相应的行动。但这种解决方案存在竞态条件：如果信号SIGINT是在调用了sigaction()函数之后，但在调用select()之前传递过去的，那么它将无法中断select()调用，因为这时候信号已经丢失了。 我们也可以尝试其他的方案，比如在信号处理器里设置一个全局标志，然后在主程序里监控这个标志，并使用sigprocmask()来阻塞那个信号直到调用了select()。然而，这些技术都不能完全消除竞态条件：因为在select()调用开始之前，总是有一段时间间隔（无论其有多么短）可以处理信号。 这个问题的传统解决方案是所谓的自管(self-pipe)技巧，通常认为是由D J Bernstein首创的。使用这个技术，程序建立一个信号处理器，该信号处理器将一个字节写入一个特别建立的管道之中，该管道的读取端也将由select()进行监控。self-pipe技术很巧妙的解决了安全的等待文件描述符变为ready状态或者需要传递信号的问题。然而，这需要通过大量的代码来解决一个实质上很简单的需求。（例如，一个健壮的解决方案需要同时标记管道的读写端） 出于此因，POSIX.1g委员会设计了一个select()的增强版本，也就是pselect()。select()与pselect()之间最主要的区别就是后者有一个sigset_t类型的信号掩码（sigmask）作为额外的参数： int pselect(int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, const struct timespec *timeout, const sigset_t *sigmask); sigmask参数指定了一个应该在pselect()调用期间阻塞的信号集合，它会在调用期间覆盖当前的信号掩码。当我们做以下调用时： ready = pselect(nfds, \u0026readfds, \u0026writefds, \u0026exceptfds, timeout, \u0026sigmask); 内核会执行一系列步骤，这相当于原子地执行以下系统调用： sigset_t sigsaved; sigprocmask(SIG_SETMASK, \u0026sigmask, \u0026sigsaved); ready = select(nfds, \u0026readfds, \u0026writefds, \u0026exceptfds, timeout); sigprocmask(SIG_SETMASK, \u0026sigsaved, NULL); glibc虽也提供了pselect()的库实现，而且实际上也是使用了上面的系统调用序列。但问题是，这种实现依然很容易受到pselect()用来避免竞态条件的设计的影响，因为单独的系统调用并不是原子的。 使用pselect()，我们可以安全地等待信号传递或者文件描述符进入ready状态，只需将我们前面的示例代码修改为： sigset_t emptyset, blockset; sigemptyset(\u0026blockset); /* Block SIGINT */ sigaddset(\u0026blockset, SIGINT); sigprocmask(SIG_BLOCK, \u0026blockset, NULL); sa.sa_handler = handler; /* Establish signal handler */ sa.sa_flags = 0; sigemptyset(\u0026sa.sa_mask); sigaction(SIGINT, \u0026sa, NULL); /* Initialize nfds and readfds, and perhaps do other work here */ /* Unblock signal, then wait for signal or ready file descriptor */ sigemptyset(\u0026emptyset); ready = pselect(nfds, \u0026readfds, NULL, NULL, NULL, \u0026emptyset); ... 这段代码可以工作，因为SIGINT信号只有在控制传递给内核之后才会被解除阻塞。因此，在pselect()执行之前，无法传递信号。如果信号是在pselect()被阻塞时生成的，那么与select()一样，系统调用将被中断，且信号将在系统调用返回之前传递完成。 虽然pselect()是在几年前构思的，也已经在1998由W. Richard Stevens在其著作*Unix Network Programming, vol. 1, 2nd ed.*中公布，但实际的实现却很晚才出现。随着2.6.16版本的释出，以及更新的glibc2.4，Linux才可以使用pselect()。 Linux 2.6.16同时也包含了一个新的（但不是标准的）ppoll()系统调用，它也是在传统的poll()接口中增加了一个信号掩码参数： int ppoll(struct pollfd *fds, nfds_t nfds, const struct timespec *timeout, const sigset_t *sigmask); ppoll()增添了与pselect()相对于select()相同的功能。为了不受冷落，epoll维护者在pipeline中添加了补丁，以新的epoll_pwait()系统调用的形式添加类似的功能。 pselect()和ppoll()与传统方法相比还有一些其他的细微差别。例如超时的类型为: struct timespec { long tv_sec; /* Seconds */ long tv_nsec; /* Nanoseconds */ }; 这允许用比以前的系统调用更高的精度来指定超时间隔。 pselect()和select()的glibc wrappers还隐藏了一些底层系统调用细节: 首先，系统调用实际上期望信号掩码由两个参数来进行描述，其中一个参数是一个指向sigset_t结构的指针，而另一个参数是一个以字节表示该结构大小的整数。这使得将来可能会有更大的sigset_t类型。 底层系统调用还修改了他们的超时参数，以便在函数提前返回时（文件描述符进入ready状态，或者传递了信号），调用方能够知道剩余的超时时间。但是，各个wrapper函数通过创建超时参数的本地副本并将该副本传递给底层系统调用来隐藏其详情。（Linux的select()也修改了其超时参数，并且对应用程序是可见的。不过许多其他的select()实现并没有修改此参数。POSIX.1承认他们之中的任何一种实现。） 有关pselect()和ppoll()的详细信息可以在man pages中查询select(2)和poll(2)。 原文： The new pselect() system call - [LWN.net] ","date":"2019-04-09","objectID":"/post/2019/04/09/the-new-pselect-system-call/:0:0","tags":["Linux"],"title":"[译]pselect()系统调用","uri":"/post/2019/04/09/the-new-pselect-system-call/"},{"categories":["Golang","后端"],"content":"Golang官方并没有提供数据库驱动，但通过database/sql/driver包来提供了实现驱动的标准接口。可以在Github上找到很多开源的驱动。 其中go-sql-driver/mysql是一个比较推荐的驱动，其完全支持database/sql接口。 使用这个驱动, 在项目里import进： import ( \"database/sql\" _ \"github.com/go-sql-driver/mysql\" ) 在正式使用database/sql包之前，首先得明白sql.DB并不代表一个数据库连接，它并不会与数据库建立任何连接，也不会验证参数的合法性，要想知道DSN的合法性，需使用sql.DB实例（比如db）db.Ping() 方法， 如下： err = db.Ping() if err != nil { // 错误处理 } 使用sql.Open()方法即可获得一个sql.DB实例。需要注意的是，sql.DB的设计就是用来作为长连接使用的，不应该在项目里频繁的进行Open() 与Close()，提倡的做法是声明一个全局的sql.DB实例, 将其复用起来。即只Open()一次，使用直到程序结束任务。 拿到sql.DB实例之后，就可以对数据库进行操作了。 在操作数据库时，推荐做法是使用db.Prepare()对SQL语句进行预编译，这样具有较高的安全性，可在一定程度上避免诸如SQL注入这样的攻击手段。 一些示例： /* 查询操作 */ stmt, err := db.Prepare(\"SELECT `user_name` FROM `users` WHERE `id` = ?\") defer stmt.Close() if err != nil { //错误处理 } var userName string //Scan() 将结果复制到userName err = stmt.QueryRow(1).Scan(\u0026userName) fmt.Println(userName) /* 多行结果 */ stmt, err := db.Prepare(\"SELECT `user_name` FROM `users` WHERE `age` = ?\") defer stmt.Close() if err != nil { //错误处理 } rows, err := stmt.Query(年龄) if err != nil { //错误处理 } for rows.Next() { var userName string if err := rows.Scan(\u0026userName); err != nil { //错误处理 } } /* 插入操作 */ stmt, err := db.Prepare(\"INSERT INTO `users` (`user_name`, `age`) VALUES(?, ?)\") defer stmt.Close() if err != nil { //错误处理 } stmt.Exec(\"名字\", 年龄) /* 事务 */ tx, err := db.Begin() if err != nil { //错误处理 } defer tx.Rollback() stmt, err := db.Prepare(\"\") defer stmt.Close() if err != nil { //错误处理 } stmt.Exec() err = tx.Commit() if err != nil { //错误处理 } ","date":"2019-03-09","objectID":"/post/2019/03/09/working-with-mysql-in-golang/:0:0","tags":["Golang"],"title":"在Golang中对MySQL进行操作","uri":"/post/2019/03/09/working-with-mysql-in-golang/"},{"categories":["Golang","后端"],"content":"在并发编程中，多线程并发协作时采用生产者消费者模式是一个良好的解决方案。生产者线程将生成的数据放入一个阻塞队列中，消费者则直接从该队列中获取数据，这样做的目的是为了降低生产者与消费者之间的耦合性，同时也平衡了两者的不对等的处理能力。 为了达到上述目的，还可以考虑采用消息中间件。由此也引出我们今天的主题：RabbitMQ。RabbitMQ实现了AMQP (Advanced Message Queue Protocol)协议，是目前广泛使用的消息中间件之一。 RabbitMQ中有几个重要的概念： Queue： 消息队列，是RabbitMQ的核心 Binding： 绑定，Exchange通过与Queue绑定并为每个Queue设置Routing Key从而达到路由功能 Channel： 消息通道，每一个Channel代表一个客户端会话任务 Exchange： 交换器，制定消息传递的规则，选择路由 Routing Key： 路由关键字，Exchange根据此项选择投递消息到哪个Queue Virtual Host： 虚拟机，用于隔离用户权限 安装RabbitMQ Archlinux: sudo pacman -S rabbitmq 安装完成之后，启动RabbitMQ： sudo systemctl start rabbitmq.service 此时，RabbitMQ就开始运行了，默认只采用AMQP协议。如果想使用网页来管理服务器，可以激活对应的插件： sudo rabbitmq-lugins enable rabbitmq_management AMQP协议的端口为5672，网页管理台端口为15672，默认用户名和密码均为guest(记得改密码！) 再将RabbitMQ重启一下： sudo systemctl restart rabbitmq.service 新建用户和虚拟机： //新建一个用户 sudo rabbitmqctl add_user username password //新建一个虚拟机 sudo rabbitmqctl add_vhost NewHost //设置用户角色 sudo rabbitmqctl set_user_tags username monitoring //设置 /NewHost对于用户username可用 sudo rabbitmqctl set_permissions -p NewHost username \".*\" \".*\" \".*\" Golang使用RabbitMQ 想要通过Golang来使用RabbitMQ（AMQP协议版）,需要下载AMQP库： go get github.com/streadway/amqp 然后编写producer.go与consumer.go两个程序： /* producer.go Author: Peven */ package main import ( \"log\" \"github.com/streadway/amqp\" ) func main() { //start a new amqp connection conn, err := amqp.Dial(\"amqp://username:password@localhost:5672/NewHost\") if err != nil { log.Fatal(err) } defer conn.Close() //declare a channel ch, err := conn.Channel() if err != nil { log.Fatal(err) } defer ch.Close() //declare a queue queue, err := ch.QueueDeclare( \"TestQueue\", //queue name true, //durable false, //auto-delete when unused false, //exclusive false, //no-wait nil, //args ) if err != nil { log.Fatal(err) } //declare a exchange err = ch.ExchangeDeclare( \"TestExchange\", //exchange name \"direct\", //type true, //durable false, //auto-delete when unused false, //internal false, //no-wait nil, //args ) if err != nil { log.Fatal(err) } //binding a queue err = ch.QueueBind( queue.Name, //queue name \"routing_key\", //routing key \"TestExchange\", //exhchange name false, //no-wait nil, //args ) if err != nil { log.Fatal(\"1:\", err) } //publish a message err = ch.Publish( \"TestExchange\", //exchange name \"routing_key\", //routing key false, //mandatory false, //immediate amqp.Publishing{ ContentType: \"text/plain\", Body: []byte(\"This is a message\"), }, ) if err != nil { log.Fatal(err) } } /* consumer.go Author: Peven */ package main import ( \"fmt\" \"log\" \"sync\" \"github.com/streadway/amqp\" ) func main() { //start a new amqp connection conn, err := amqp.Dial(\"amqp://username:password@localhost:5672/NewHost\") if err != nil { log.Fatal(err) } defer conn.Close() //declare a channel ch, err := conn.Channel() if err != nil { log.Fatal(err) } defer ch.Close() //declare a queue queue, err := ch.QueueDeclare( \"TestQueue\", //queue name true, //durable false, //auto-delete when unused false, //exclusive false, //no-wait nil, //args ) if err != nil { log.Fatal(err) } //get the delivery results msgs, err := ch.Consume( queue.Name, // queue name \"peven\", // consumer name true, // auto-ack false, // exclusive false, // no-local false, // no-wait nil, // args ) var wg sync.WaitGroup wg.Add(1) go func() { for m := range msgs { fmt.Println(\"Receive a message: \", string(m.Body)) } }() wg.Done() } 运行完producer之后，打开终端输入以下命令查看Exchange： sudo rabbitmqctl list_exchanges -p NewHost 输出如下： Listing exchanges for vhost NewHost ... name type amq.topic topic amq.direct direct TestExchange direct //新创建的交换器 amq.fanout fanout amq.rabbitmq.trace topic amq.match headers amq.headers headers direct //默认路由，\"\" 输入sudo rabbitctl list_bindings -p NewHost 查看建立的绑定： $ sudo rabbitmqctl list_bindings -p NewHost --no-table-headers Listing bindings for vhost NewHost... exchange TestQueue queue TestQueue [] TestExchange exchange TestQueue queue routing_key [] 同时，运行consumer也打印出了producer发送的消息。 ","date":"2019-02-03","objectID":"/post/2019/02/03/learn-rabbitmq-with-golang/:0:0","tags":["Golang","RabbitMQ"],"title":"RabbitMQ初涉以及Golang实践","uri":"/post/2019/02/03/learn-rabbitmq-with-golang/"},{"categories":["Golang"],"content":"在Golang中使用for range语句进行迭代非常的便捷，但在涉及到指针时就得小心一点了。 下面的代码中定义了一个元素类型为*int的通道ch： package main import ( \"fmt\" ) func main() { ch := make(chan *int, 5) //sender input := []int{1,2,3,4,5} go func(){ for _, v := range input { ch \u003c- \u0026v } close(ch) }() //receiver for v := range ch { fmt.Println(*v) } } 在上面代码中，发送方将input数组发送给ch通道，接收方再从ch通道中接收数据，程序的预期输出应该是： 1 2 3 4 5 现在运行一下程序，得到的输出如下： 5 5 5 5 5 很明显，程序并没有达到预期的结果，那么问题出在哪里呢？我们将代码稍作修改： //receiver for v := range ch { fmt.Println(v) } 得到如下输出： 0x416020 0x416020 0x416020 0x416020 0x416020 可以看到，5次输出变量v（*int）都指向了同一个地址，返回去检查一下发送部分代码： for _, v := range input { ch \u003c- \u0026v } 问题正是出在这里，在for range语句中，v变量用于保存迭代input数组所得的值，但是v只被声明了一次，此后都是将迭代input出的值赋值给v，v变量的内存地址始终未变，这样再将v的地址发送给ch通道，发送的都是同一个地址，当然无法达到预期效果。 解决方案是，引入一个中间变量，每次迭代都重新声明一个变量temp，赋值后再将其地址发送给ch： for _, v := range input { temp := v ch \u003c- \u0026temp } 抑或直接引用数据的内存（推荐，无需开辟新的内存空间）： for k, _ := range input { c \u003c- \u0026input[k] } 再次运行，就可看到预期的效果。以上方案是用于讨论range语句带来的问题，当然，平时还是尽量避免使用指针类型元素的通道。 ","date":"2019-02-01","objectID":"/post/2019/02/01/golang-range-pointer-problem/:0:0","tags":["Golang"],"title":"Golang中range指针数据的坑","uri":"/post/2019/02/01/golang-range-pointer-problem/"},{"categories":["折腾","Linux"],"content":"操作环境： 支持浏览器VNC方式登录的云服务商（e.g. 阿里云、腾讯云） Ubuntu 16.04 服务器 ","date":"2018-12-07","objectID":"/post/2018/12/07/replace-server-os-with-archlinux/:0:0","tags":["Archlinux"],"title":"替换云服务器操作系统为Archlinux","uri":"/post/2018/12/07/replace-server-os-with-archlinux/"},{"categories":["折腾","Linux"],"content":"准备工作 对于不支持DHCP的厂商，需要我们自己去手动配置服务器的内网IP地址: 使用ip addr命令获取IP地址信息并记录下来，在搞完事情后需要我们根据这些信息手动设置服务器IP。在这里假设我的IP地址172.18.65.234/18，其对应的网关地址为172.18.64.1。 ","date":"2018-12-07","objectID":"/post/2018/12/07/replace-server-os-with-archlinux/:1:0","tags":["Archlinux"],"title":"替换云服务器操作系统为Archlinux","uri":"/post/2018/12/07/replace-server-os-with-archlinux/"},{"categories":["折腾","Linux"],"content":"开始安装 ","date":"2018-12-07","objectID":"/post/2018/12/07/replace-server-os-with-archlinux/:2:0","tags":["Archlinux"],"title":"替换云服务器操作系统为Archlinux","uri":"/post/2018/12/07/replace-server-os-with-archlinux/"},{"categories":["折腾","Linux"],"content":"下载镜像 下载最新archlinux镜像到根目录下： root@Ali:~# cd / root@Ali:/# wget https://mirrors.tuna.tsinghua.edu.cn/archlinux/iso/latest/archlinux-2018.12.01-x86_64.iso ","date":"2018-12-07","objectID":"/post/2018/12/07/replace-server-os-with-archlinux/:2:1","tags":["Archlinux"],"title":"替换云服务器操作系统为Archlinux","uri":"/post/2018/12/07/replace-server-os-with-archlinux/"},{"categories":["折腾","Linux"],"content":"查看磁盘信息 root@Ali:/# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT vda 254:0 0 40G 0 disk `-vda1 254:1 0 40G 0 part / ","date":"2018-12-07","objectID":"/post/2018/12/07/replace-server-os-with-archlinux/:2:2","tags":["Archlinux"],"title":"替换云服务器操作系统为Archlinux","uri":"/post/2018/12/07/replace-server-os-with-archlinux/"},{"categories":["折腾","Linux"],"content":"引导iso文件 在Ubuntu里编辑/boot/grub/grub.cfg文件，添加下列内容： #timeout设为60,是为了VNC连接时有足够时间选择启动项，若为第一启动项，可不设置 set timeout=60 menuentry 'ArchISO' --class iso { set isofile=/archlinux-2018.12.01-x86_64.iso loopback loop0 $isofile #archisolabel设置archiso文件驻留的文件系统标签。 #img_dev指明archiso文件驻留的设备 #img_loop是archiso文件在img_dev里的绝对位置 linux (loop0)/arch/boot/x86_64/vmlinuz archisolabel=ARCH20181201 img_dev=/dev/vda1 img_loop=$isofile initrd (loop0)/arch/boot/x86_64/archiso.img } 然后重启，同时在浏览器里以VNC方式连接到服务器，在GRUB启动菜单里选择ArchISO进入。 ","date":"2018-12-07","objectID":"/post/2018/12/07/replace-server-os-with-archlinux/:2:3","tags":["Archlinux"],"title":"替换云服务器操作系统为Archlinux","uri":"/post/2018/12/07/replace-server-os-with-archlinux/"},{"categories":["折腾","Linux"],"content":"安装Archlinux 进入Archlinux Live环境后，使用lsblk命令，你会发现我们的目标磁盘/dev/vda1被挂载到了/run/archiso/img_dev目录下。清楚了这一点后，就可以按照ArchWiki的介绍开始安装ArchLinux了，只需将步骤里的/mnt换为/run/archiso/img_dev即可。有可能需要mount -o remount,rw /run/archiso/img_dev。 ","date":"2018-12-07","objectID":"/post/2018/12/07/replace-server-os-with-archlinux/:2:4","tags":["Archlinux"],"title":"替换云服务器操作系统为Archlinux","uri":"/post/2018/12/07/replace-server-os-with-archlinux/"},{"categories":["折腾","Linux"],"content":"联网 安装完成后，重启进入系统（浏览器VNC登录状态），使用ip link命令查看设备，使用ip addr add ip地址 dev 设备设置IP,使用ip route add default via 网关 dev 设备配置网关地址。 root@arch:~# ip link #查看设备 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: ens3: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000 link/ether 00:16:3e:0e:e4:6b brd ff:ff:ff:ff:ff:ff root@arch:~# ip link set ens3 up root@arch:~# ip addr add 172.18.65.234/18 dev ens3 root@arch:~# ip route add default via 172.18.64.1 dev ens3 root@arch:~# echo 'nameserver 8.8.8.8' \u003e /etc/resolv.conf 大功告成！ ","date":"2018-12-07","objectID":"/post/2018/12/07/replace-server-os-with-archlinux/:2:5","tags":["Archlinux"],"title":"替换云服务器操作系统为Archlinux","uri":"/post/2018/12/07/replace-server-os-with-archlinux/"},{"categories":["折腾","Linux"],"content":"Reference README.bootparams https://git.archlinux.org/archiso.git/tree/docs/README.bootparams GUN GRUB Manual https://www.gnu.org/software/grub/manual/grub/grub.html Multiboot USB drive - ArchWiki https://wiki.archlinux.org/index.php/Multiboot_USB_drive#Arch_Linux_monthly_release ","date":"2018-12-07","objectID":"/post/2018/12/07/replace-server-os-with-archlinux/:3:0","tags":["Archlinux"],"title":"替换云服务器操作系统为Archlinux","uri":"/post/2018/12/07/replace-server-os-with-archlinux/"},{"categories":["折腾"],"content":"服务器环境： Archlinux Nginx1.15.6（自行编译） （1）安装Certbot sudo pacman -S certbot （2）开始签发 因为我的Nginx是自行编译的，所以无法使用certbot的nginx plugin,我选择手动验证dns来进行签发 sudo certbot certonly --preferred-challenges dns -d \"*.example.com\" -d example.com --manual 在这里，我指定了两个-d参数，因为certbot的泛域名其实只支持诸如*.example.com，如要直接使用顶域，就得为其单独也签发一条。 回车之后，certbot会让你去给你的域名添加2条TXT记录，名称为_acme-challenge.example.com（TXT记录可重复） （3）检查解析记录 在添加完上述TXT记录后，在另一个终端输入： nslookup -type=txt _acme-challenge.example.com 8.8.8.8 如果返回结果中有你添加的两条TXT记录值，那么说明解析已经生效了。这个时候再返回签发状态的certbot所在终端，回车，不出意外的话，certbot会在输出结果里打印出证书签发好之后存放的位置，找到它们，就OK了。 ","date":"2018-12-04","objectID":"/post/2018/12/04/free-ssl-with-certbot/:0:0","tags":["SSL","Nginx"],"title":"使用Certbot签发免费泛域名SSL证书","uri":"/post/2018/12/04/free-ssl-with-certbot/"},{"categories":["Linux","后端"],"content":"Process Credentials包含一系列的ID： real user ID \u0026 real group ID effective user ID \u0026 effective group ID saved set-user-ID \u0026 saved set-group-ID file-system user ID \u0026 file-system group ID supplementary group IDs real user ID \u0026 real group ID real user ID和real gourp ID确定了进程所属的用户与组。在登陆过程中（只讨论终端登陆情况），init进程调用getty完成用户名与密码的输入后，login进程会从/etc/passwd文件中读取相应用户密码记录的第三字段（UID）和第四字段（GID），并调用setuid()设定登陆成功后对应Shell进程的real user ID与real group ID。即real user ID（real group ID）用于标识当前用户（组）是谁。 可使用logname命令获取real user ID： ┌─[peven@Arch] - [~] - [Sat Dec 01, 16:03] └─[$] \u003c\u003e logname peven effective user ID \u0026 effective group ID 一般而言，effective user ID（effective group ID）是与real user ID（real group ID）相同的，但当我们的程序需要额外的权限去访问他们没有权限访问的资源时，他们就需要将自己的user ID或group ID改为一个具有适当权限的ID（effective user/group ID）。这可以通过调用setuid()，setgid()来实现。 effective user ID 可以通过whoami命令来查看： ┌─[peven@Arch] - [~] - [Sat Dec 01, 16:18] └─[$] \u003c\u003e whoami peven ┌─[peven@Arch] - [~] - [Sat Dec 01, 16:18] └─[$] \u003c\u003e su #切换为root用户 Password: [root@Arch peven]# logname #可以看到当前Shell的real user ID仍为peven peven [root@Arch peven]# whoami #effctive user ID变成了root root saved set-user-ID \u0026 saved set-group-ID 在设计程序时，应当遵守最小权限准则，以减少恶意用户试图欺骗我们的程序以非预期的方式使用其特权而损害安全性的可能性。saved set-user-ID（saved set-group-ID）是与set-user-ID（set-group-ID）程序结合使用的。 此名称中的saved保存的实际是effective user ID（effective group ID）。 若可执行文件的set uid/gid权限位开启（eg. chmod u+s a.out），则将进程的effective user/group ID置为可执行文件的属主。否则，进程的effective user/group ID将保持不变。 无论可执行文件的set /uid/gid权限位是否开启，saved set-user-ID（saved set-group-ID）对effective user/group ID值的复制都会进行。 比如我们有一个程序，其作用是打印real user ID，effective user ID以及saved set-user-ID: /* res.c */ #define _GNU_SOURCE #include \u003cunistd.h\u003e #include \u003cstdio.h\u003e int main(void) { uid_t ruid, euid, suid; getresuid(\u0026ruid, \u0026euid, \u0026suid); printf(\"real user ID: %d\\neffective user ID: %d\\nsaved set-user-ID: %d\\n\", ruid, euid, suid); return 0; } 其权限为： -rwxr-xr-x 1 peven users 17K Dec 1 17:17 res.o 编译运行： 在未开启set uid/gid权限位时，以普通用户运行： real user ID: 1000 effective user ID: 1000 saved set-user-ID: 1000 root用户： real user ID: 0 effective user ID: 0 saved set-user-ID: 0 开启set uid/gid权限位后（chmod u+s res.o），普通用户： real user ID: 1000 effective user ID: 1000 saved set-user-ID: 1000 root用户： real user ID: 0 effective user ID: 1000 saved set-user-ID: 1000 file-system user ID \u0026 file-system group ID. file-system user/group ID始见于Linux1.2版本，当时如果某进程甲的effective user ID等同于某进程乙的real user ID或effective user ID，那么甲就可以向乙发送信号。file-system user/group ID就是为了防范这一风险而生的。不过从Linux2.0版本起，Linux开始在信号发送权限方面遵循SUSv3所强制规定的规则，且这些规则不再涉及目标进程的effective user ID。这样看来，file-system user/group ID在今天已经可以废除了。但为了保持软件的兼容性，还是将其保留了下来。 supplementary group IDs supplementary group IDs用于标识进程所属的若干附加的组。supplementary group IDs会配合file-system ID和effective ID来进行进程是否有访问某些资源权限的判定。 ","date":"2018-12-01","objectID":"/post/2018/12/01/linux-process-credentials/:0:0","tags":["Linux"],"title":"Linux Process Credentials","uri":"/post/2018/12/01/linux-process-credentials/"},{"categories":["Linux","后端"],"content":"最近在学习容器时，遇到了以下几个系统调用，遂作个记录 chdir：更改工作目录 chroot：更改root目录 ","date":"2018-11-25","objectID":"/post/2018/11/25/chdir-and-chroot/:0:0","tags":["Linux"],"title":"Chdir()与Chroot()","uri":"/post/2018/11/25/chdir-and-chroot/"},{"categories":["Linux","后端"],"content":"chdir #include \u003cunistd.h\u003e int chdir(const char *path); 示例 chdir将当前目录改为当前目录下的test目录,而fork出的子程序也继承了这个目录 /* chdir.c */ #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003csys/types.h\u003e int main(void) { pid_t pid; if(chdir(\"./test\") != 0) { printf(\"chdir error\\n\"); } pid = fork(); if(pid == 0) { printf(\"Child dir: %s\\n\", get_current_dir_name()); }else { printf(\"Parent dir: %s\\n\", get_current_dir_name()); } return 0; } ","date":"2018-11-25","objectID":"/post/2018/11/25/chdir-and-chroot/:0:1","tags":["Linux"],"title":"Chdir()与Chroot()","uri":"/post/2018/11/25/chdir-and-chroot/"},{"categories":["Linux","后端"],"content":"chroot 每一个进程都有一个根目录，一般是对应文件系统的真实根目录，且每个进程都会继承其父进程的根目录。可以通过chroot()来改变一个进程的根目录。此后，所有绝对路径的解释都将从该目录开始（即假装自己是那个/）。chroot()并不改变当前工作目录。 #include \u003cunistd.h\u003e int chroot(const char *path); chroot()必须与chdir()一同使用，否则程序将有可能通过使用相对路径来进行“越狱”。为避免“越狱”情况的发生，同时还应该将程序中之前打开的“狱外”文件都关闭，因为使用fchdir()可以通过之前打开的文件描述符而达到越狱的目的。 示例 /* chroot.c */ #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e int main(void) { FILE *f; /* * Or: * chdir(\"./jail\"); * chroot(\"./\"); */ if(chroot(\"./jail\") != 0) { perror(\"chroot() error\"); } if(chdir(\"/\") != 0) { perror(\"chdir() error\"); } /* do something after chrooting */ f = fopen(\"/in_jail.txt\", \"r\"); if(f == NULL) { perror(\"/in_jail.txt error\"); }else { char buf[100]; while(fgets(buf, sizeof(buf), f)) { printf(\"%s\\n\", buf); } } return 0; } 我的目录结构： . |-- chroot.c |-- chroot.o |-- out_of_jail.txt `-- jail `-- in_jail.txt 再看一个越狱的例子： /* chroot_breaking_out_jial.c */ #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e #include \u003cfcntl.h\u003e int main(void) { int f1; FILE *f2; f1 = open(\"/\", O_RDONLY); if(chroot(\"./test\") != 0) { perror(\"chroot() error\"); } if(chdir(\"/\") != 0) { perror(\"chdir() error\"); } /* close(f1); */ /* Breaking out the jail */ fchdir(f1); chroot(\".\"); printf(\"%s\\n\", get_current_dir_name()); f2 = fopen(\"/root/WORK/out_of_jail.txt\", \"r\"); if(f2 == NULL) { perror(\"out_of_jail_txt error\"); }else { char buf[100]; while(fgets(buf, sizeof(buf), f2)) { printf(\"%s\\n\", buf); } } return 0; } ","date":"2018-11-25","objectID":"/post/2018/11/25/chdir-and-chroot/:0:2","tags":["Linux"],"title":"Chdir()与Chroot()","uri":"/post/2018/11/25/chdir-and-chroot/"},{"categories":["折腾"],"content":"契机 Windows10的WSL[Windows Subsystem for Linux]在2017秋季更新后修复了大量的BUG。不过对于WSL,之前我一直处于围观状态，嗯，作为一位狂热Linuxer，怎么能随便投身Windows呢呵呵。 在最初的时候，WSL还只有Ubuntu，到现在应用商店里提供了有Fedora、Debian、SUSE和KALI。呃…等等，怎么能没有我们优秀的Archlinux呢？作为Archlinuxer第一个不服。 恰巧前几天逛论坛时看到了几篇关于在WSL上安装其他发行版本的文章，于是我也打开了久违的Windows(据说优秀的人都有两块硬盘的……嗯)，琢磨着把Archlinux给捣鼓进去。于是看了看网上的教程，然后结合自己的骚操作，作文以记之。 ","date":"2018-06-18","objectID":"/post/2018/06/18/replace-ubuntu-on-wsl-with-archlinux/:1:0","tags":["Archlinux","WSL","Linux"],"title":"Replace Ubuntu on WSL with Archlinux","uri":"/post/2018/06/18/replace-ubuntu-on-wsl-with-archlinux/"},{"categories":["折腾"],"content":"搞事情 1.首先呢，安装WSL(我装的Ubuntu18.04)对吧(这你肯定会的吧，不然你就是不优秀)。 2.将Ubuntu的默认用户改为root，打开PowerShell，键入: ubuntu1804 config --default-user root 3.安装Archlinux 3.1下载Archlinux根镜像airootfs.sfs： wget https://mirrors.tuna.tsinghua.edu.cn/archlinux/iso/latest/arch/x86_64/airootfs.sfs 这是一个squashfs格式的文件，我们需要用到squashfs-tools来解压它。 3.2 解压根镜像： sudo apt install squashfs-tools unsquashfs airootfs.sfs 解压得到squashfs-root文件夹 3.3替换ubuntu 关闭Bash窗口，进入Windows文件资源管理器，找到C:\\Users\\{用户名}\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu*\\LocalState\\rootfs文件夹，重命名备份为rootfs-root，将rootfs-old/root/squashfs-root文件夹复制到rootfs-root的同级目录，并将其重命名为rootfs。 3.4善后 再次打开我们的Ubuntu1804，就可以发现他已经变身成为Archlinux了(掌声、、、咳咳、、、低调)。 现在，我们需要初始化pacman的密钥： pacman-key --init 这样就可以建立新密钥并生成系统主密钥，然后，验证咱们的主密钥： pacman-key --populate archlinux 然后我就兴奋的用pacman搞事情了，然后… 我就遇到了一系列的： error:*!@×@$*^%@\u0026*% (unable to lock database) 这时候，我们只需要把旧锁给删掉就可以正常搞！事！情！了 rm /var/lib/pacman/db.lck 新建一个用户，并加入sudo: useradd -m -g users -G wheel peven nano /etc/sudoers #添加 peven ALL=(ALL) ALL 关闭Bash窗口，再次打开PowerShell，将默认用户改为peven: ubuntu1804 config --default-user peven 没生效或者出现问题，重启大法好。 ","date":"2018-06-18","objectID":"/post/2018/06/18/replace-ubuntu-on-wsl-with-archlinux/:2:0","tags":["Archlinux","WSL","Linux"],"title":"Replace Ubuntu on WSL with Archlinux","uri":"/post/2018/06/18/replace-ubuntu-on-wsl-with-archlinux/"},{"categories":["折腾"],"content":"Duang~ Duang~ Duang~ peven@ArchWSL ~ % neofetch -` peven@ArchWSL .o+` ------------- `ooo/ OS: Arch Linux on Windows 10 x86_64 `+oooo: Kernel: 4.4.0-17134-Microsoft `+oooooo: Uptime: 1 min -+oooooo+: Shell: zsh 5.5.1 `/:-:++oooo+: Terminal: /dev/tty1 `/++++/+++++++: CPU: Intel i5-8250U (8) @ 1.800GHz `/++++++++++++++: Memory: 1776MiB / 8089MiB `/+++ooooooooooooo/` ./ooosssso++osssssso+` .oossssso-````/ossssss+` -osssssso. :ssssssso. :osssssss/ osssso+++. /ossssssss/ +ssssooo/- `/ossssso+/:- -:/+osssso+- `+sso+:-` `.-/+oso: `++:. `-/+/ .` `/ 完了你问体验？呵呵，回Windows是不可能回的，这辈子都不可能的。 ","date":"2018-06-18","objectID":"/post/2018/06/18/replace-ubuntu-on-wsl-with-archlinux/:3:0","tags":["Archlinux","WSL","Linux"],"title":"Replace Ubuntu on WSL with Archlinux","uri":"/post/2018/06/18/replace-ubuntu-on-wsl-with-archlinux/"},{"categories":["折腾"],"content":"Referrence Install on WSL: https://wiki.archlinux.org/index.php/Install_on_WSL Install from existing Linux: https://wiki.archlinux.org/index.php/Install_from_existing_Linux ","date":"2018-06-18","objectID":"/post/2018/06/18/replace-ubuntu-on-wsl-with-archlinux/:4:0","tags":["Archlinux","WSL","Linux"],"title":"Replace Ubuntu on WSL with Archlinux","uri":"/post/2018/06/18/replace-ubuntu-on-wsl-with-archlinux/"},{"categories":null,"content":"Info  PEVEN PHOON 🇨🇳  @PevenPhoon  https://github.com/phoon  echo 'aWFtcGV2ZW5AZ21haWwuY29tCg==' | base64 -d  0xCAEABF9DA3C8C09A [check]  BEB0 A7E9 9B80 9D09 A109 B376 CAEA BF9D A3C8 C09A  https://keybase.io/pevenphoon ","date":"0001-01-01","objectID":"/about/:1:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"Skills  OS/LINUX Daily use of Archlinux for years KDE Plasma user，always want to hang out withi3wm/dwm，but u know… AURprimary packager Vim+Tmux  PL Go \u0026 C ","date":"0001-01-01","objectID":"/about/:2:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":" NICKNAME LINK NickCao https://nichi.co 艾雨寒·ArielAxionL https://axionl.me 惠狐·MarvelousBlack https://blog.megumifox.com/public Astrian Zheng https://astrianzheng.cn weearc https://blog.weearc.top 爱德华·Edward P https://blog.edward-p.xyz Mike Yuan https://yhndnzj.com ","date":"0001-01-01","objectID":"/friends/:0:0","tags":null,"title":"FRIENDS","uri":"/friends/"}]